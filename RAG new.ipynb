{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ywangumichigan/EECS595-Project/blob/main/RAG%20new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "awYzAGIBtxzs",
      "metadata": {
        "id": "awYzAGIBtxzs"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet wikipedia\n",
        "!pip install --quiet nltk\n",
        "!pip install --quiet gensim\n",
        "!pip install --quiet faiss-cpu\n",
        "!pip install --quiet langchain-text-splitters\n",
        "!pip install --quiet transformers\n",
        "!pip install --quiet torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e4be5939-c972-4aed-9ffd-c28247c1d6a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4be5939-c972-4aed-9ffd-c28247c1d6a1",
        "outputId": "f1e61861-8352-4b29-950a-9616da813f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collected: Algebra\n",
            "Collected: Calculus\n",
            "Skipped Derivative\n",
            "Collected: Integral\n",
            "Collected: Matrix (mathematics)\n",
            "Collected: Probability\n",
            "Collected: Statistics\n",
            "Collected: Geometry\n",
            "Collected: Trigonometry\n",
            "Collected: Number theory\n"
          ]
        }
      ],
      "source": [
        "# --- Imports ---\n",
        "import nltk\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import faiss\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# --- Download tokenizer data ---\n",
        "nltk.download('punkt')\n",
        "\n",
        "# --- Step 1: Collect Wikipedia data ---\n",
        "import wikipedia\n",
        "\n",
        "topics = [\"Algebra\", \"Calculus\", \"Derivative\", \"Integral\",\n",
        "          \"Matrix (mathematics)\", \"Probability\", \"Statistics\",\n",
        "          \"Geometry\", \"Trigonometry\", \"Number theory\"]\n",
        "\n",
        "wiki_corpus = []\n",
        "for topic in topics:\n",
        "    try:\n",
        "        page = wikipedia.page(topic)\n",
        "        wiki_corpus.append({\"title\": topic, \"content\": page.content})\n",
        "        print(f\"Collected: {topic}\")\n",
        "    except:\n",
        "        print(f\"Skipped {topic}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "90e1c97c-5a42-4246-b755-a7f08b71df22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90e1c97c-5a42-4246-b755-a7f08b71df22",
        "outputId": "4d4b5038-4384-455d-c943-57221f4feac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks: 1391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# --- Step 2: Split long pages into smaller chunks ---\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,      # around 500 characters per chunk\n",
        "    chunk_overlap=100,   # slight overlap to preserve context\n",
        ")\n",
        "\n",
        "chunks = []\n",
        "titles = []\n",
        "for doc in wiki_corpus:\n",
        "    doc_chunks = splitter.split_text(doc[\"content\"])\n",
        "    chunks.extend(doc_chunks)\n",
        "    titles.extend([doc[\"title\"]] * len(doc_chunks))\n",
        "\n",
        "print(\"Total chunks:\", len(chunks))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "af9b260e-eda7-4712-b3cc-de26be162282",
      "metadata": {
        "id": "af9b260e-eda7-4712-b3cc-de26be162282"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Step 3: Train Word2Vec embeddings on all chunks ---\n",
        "sentences = [word_tokenize(chunk.lower()) for chunk in chunks]\n",
        "model_w2v = Word2Vec(sentences, vector_size=200, window=5, min_count=1, sg=1)\n",
        "\n",
        "# --- Step 4: Turn each chunk into a vector ---\n",
        "def doc_vector(model, text):\n",
        "    words = [w for w in word_tokenize(text.lower()) if w in model.wv]\n",
        "    if len(words) == 0:\n",
        "        return np.zeros(model.vector_size)\n",
        "    return np.mean(model.wv[words], axis=0)\n",
        "\n",
        "doc_vectors = np.array([doc_vector(model_w2v, chunk) for chunk in chunks])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2073480e-cc79-47be-940f-671806dac0d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2073480e-cc79-47be-940f-671806dac0d9",
        "outputId": "c4255623-f820-4dee-863b-b3156dd8c305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indexed 1391 chunks\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Step 5: Create FAISS index ---\n",
        "d = model_w2v.vector_size\n",
        "index = faiss.IndexFlatL2(d)\n",
        "index.add(doc_vectors.astype(\"float32\"))\n",
        "print(\"Indexed\", index.ntotal, \"chunks\")\n",
        "\n",
        "# --- Step 6: Define retrieval + answer function ---\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "4b5d5ae4-5dd6-4d71-9ee9-a162cc81dfbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "4b5d5ae4-5dd6-4d71-9ee9-a162cc81dfbe",
        "outputId": "5990e7d4-4078-4db5-f560-21d1afbef795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top related titles: ['Probability', 'Statistics', 'Geometry']\n",
            "\n",
            "LLM Answer:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'unanswerable'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "\n",
        "def ask(query, k=3):\n",
        "    # Embed query\n",
        "    query_vec = doc_vector(model_w2v, query).astype(\"float32\").reshape(1, -1)\n",
        "\n",
        "    D, I = index.search(query_vec, k)\n",
        "    retrieved_chunks = [chunks[i][:1000] for i in I[0]]\n",
        "    context = \"\\n\\n\".join(retrieved_chunks)\n",
        "\n",
        "    # Build prompt\n",
        "    prompt = f\"\"\"\n",
        "    Please answer the question based on the retrieved context below.\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Question: {query}\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate answer\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=150)\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Top related titles:\", [titles[i] for i in I[0]])\n",
        "    print(\"\\nLLM Answer:\\n\")\n",
        "    return answer\n",
        "\n",
        "# --- Step 7: Example queries ---\n",
        "ask(\"what's the result of 1+1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "JpbYdvg6N3y4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpbYdvg6N3y4",
        "outputId": "58912bb4-71d0-4936-84a2-c3e81ef33a66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain version: 1.1.0\n"
          ]
        }
      ],
      "source": [
        "import langchain\n",
        "\n",
        "print(\"LangChain version:\", langchain.__version__)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9fd12bdd-2092-4d0b-8e8d-a46d2a1a8e0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fd12bdd-2092-4d0b-8e8d-a46d2a1a8e0b",
        "outputId": "52bfe7c6-83a0-481e-b882-f97a77523ff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collected: Algebra\n",
            "Collected: Calculus\n",
            "Skipped: Derivative\n",
            "Collected: Integral\n",
            "Collected: Matrix (mathematics)\n",
            "Collected: Probability\n",
            "Collected: Statistics\n",
            "Collected: Geometry\n",
            "Collected: Trigonometry\n",
            "Collected: Number theory\n",
            "Total chunks: 851\n"
          ]
        }
      ],
      "source": [
        "# --- Install dependencies ---\n",
        "!pip install --quiet wikipedia langchain langchain-community langchain-text-splitters faiss-cpu sentence-transformers transformers\n",
        "\n",
        "# --- Imports ---\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# --- Step 1: Collect small Wikipedia sample ---\n",
        "import re\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "import wikipedia\n",
        "\n",
        "topics = [\"Algebra\", \"Calculus\", \"Derivative\", \"Integral\",\n",
        "          \"Matrix (mathematics)\", \"Probability\", \"Statistics\",\n",
        "          \"Geometry\", \"Trigonometry\", \"Number theory\"]\n",
        "\n",
        "def prune_wiki(text):\n",
        "    stop_markers = [\n",
        "        \"== See also ==\",\n",
        "        \"== References ==\",\n",
        "        \"== External links ==\",\n",
        "        \"== Further reading ==\"\n",
        "    ]\n",
        "    for marker in stop_markers:\n",
        "        idx = text.find(marker)\n",
        "        if idx != -1:\n",
        "            text = text[:idx]\n",
        "    return text\n",
        "\n",
        "raw_docs = []\n",
        "for topic in topics:\n",
        "    try:\n",
        "        page = wikipedia.page(topic)\n",
        "        content = prune_wiki(page.content)\n",
        "        raw_docs.append({\"title\": topic, \"content\": content})\n",
        "        print(\"Collected:\", topic)\n",
        "    except:\n",
        "        print(\"Skipped:\", topic)\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=800,\n",
        "    chunk_overlap=150,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
        ")\n",
        "\n",
        "docs = []\n",
        "for d in raw_docs:\n",
        "    chunks = splitter.create_documents(\n",
        "        [d[\"content\"]],\n",
        "        metadatas=[{\"title\": d[\"title\"]}]\n",
        "    )\n",
        "    docs.extend(chunks)\n",
        "\n",
        "print(\"Total chunks:\", len(docs))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "PEYRLlRockFd",
      "metadata": {
        "id": "PEYRLlRockFd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "idMJUpzhPrHT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idMJUpzhPrHT",
        "outputId": "9d53012c-9d09-4bb1-92b0-8f4796a0eba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks: 1391\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# --- Step 2: Split into small text chunks ---\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "\n",
        "# adjust the keys here to match your actual dict structure\n",
        "texts = [item[\"content\"] for item in wiki_corpus]\n",
        "metadatas = [{\"title\": item.get(\"title\", \"\")} for item in wiki_corpus]\n",
        "\n",
        "docs = splitter.create_documents(texts, metadatas=metadatas)\n",
        "print(\"Total chunks:\", len(docs))\n",
        "\n",
        "# --- Step 3: Create embeddings and FAISS vectorstore ---\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
        ")\n",
        "\n",
        "vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_type=\"mmr\",\n",
        "    search_kwargs={\"k\": 6, \"lambda_mult\": 0.7}\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "JB3MlKDhQfXK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB3MlKDhQfXK",
        "outputId": "6b8594c5-1769-4230-9490-da4333f12137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "from langchain_community.llms import HuggingFacePipeline  # make sure this import is from langchain_community\n",
        "\n",
        "# --- Step 4: Load small question-answering model ---\n",
        "model_id = \"google/flan-t5-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
        "pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=150)\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipe)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "jlOXUdbIQiCU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlOXUdbIQiCU",
        "outputId": "7160d80f-7d1b-4510-d939-56fe8f079623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 1 s + 1 2 s + 1 3 s\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# --- Step 5: Build QA chain with  customprompt ---\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=(\n",
        "        \"Use the following context to answer the question concisely.\\n\\n\"\n",
        "        \"Context:\\n{context}\\n\\n\"\n",
        "        \"Question:\\n{question}\\n\\n\"\n",
        "        \"Answer:\"\n",
        "    ),\n",
        "    input_variables=[\"context\", \"question\"],\n",
        ")\n",
        "\n",
        "def format_docs(docs):\n",
        "    # docs is a list of Document objects from your retriever\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# RAG chain: question (str) -> answer (str)\n",
        "qa_chain = (\n",
        "    {\n",
        "        \"context\": retriever | format_docs,   # retrieve docs then format\n",
        "        \"question\": RunnablePassthrough(),    # pass the original question through\n",
        "    }\n",
        "    | prompt                                  # fill the PromptTemplate\n",
        "    | llm                                     # your HuggingFacePipeline LLM\n",
        "    | StrOutputParser()                       # get back a plain string\n",
        ")\n",
        "\n",
        "# Example query\n",
        "question = \"What is the result of 1+1?\"\n",
        "answer = qa_chain.invoke(question)\n",
        "print(answer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ZR7FLSdzQmna",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZR7FLSdzQmna",
        "outputId": "07a17bd8-bdb4-4ed9-d76a-a43570acd5b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: What is the volume of a box with a height of 6 cm, width 7 cm, and length 9 cm?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'replace'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1955170858.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"What is the volume of a box with a height of 6 cm, width 7 cm, and length 9 cm?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nQuery:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nAnswer:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqa_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"result\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mquery2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Who discovered calculus?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3125\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3126\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3127\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3128\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3129\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3852\u001b[0m                 ]\n\u001b[1;32m   3853\u001b[0m                 output = {\n\u001b[0;32m-> 3854\u001b[0;31m                     \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3855\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3856\u001b[0m                 }\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_invoke_step\u001b[0;34m(step, input_, config, key)\u001b[0m\n\u001b[1;32m   3835\u001b[0m             )\n\u001b[1;32m   3836\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_config\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3837\u001b[0;31m                 return context.run(\n\u001b[0m\u001b[1;32m   3838\u001b[0m                     \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3839\u001b[0m                     \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3125\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3126\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3127\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3128\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3129\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/retrievers.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mkwargs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expects_other_args\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_arg_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 result = self._get_relevant_documents(\n\u001b[0m\u001b[1;32m    217\u001b[0m                     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/vectorstores/base.py\u001b[0m in \u001b[0;36m_get_relevant_documents\u001b[0;34m(self, query, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs_and_similarities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mmr\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_marginal_relevance_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"search_type of {self.search_type} not allowed.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/vectorstores/faiss.py\u001b[0m in \u001b[0;36mmax_marginal_relevance_search\u001b[0;34m(self, query, k, fetch_k, lambda_mult, filter, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mDocuments\u001b[0m \u001b[0mselected\u001b[0m \u001b[0mby\u001b[0m \u001b[0mmaximal\u001b[0m \u001b[0mmarginal\u001b[0m \u001b[0mrelevance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         \"\"\"\n\u001b[0;32m--> 870\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embed_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m         docs = self.max_marginal_relevance_search_by_vector(\n\u001b[1;32m    872\u001b[0m             \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/vectorstores/faiss.py\u001b[0m in \u001b[0;36m_embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_embed_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/embeddings/huggingface.py\u001b[0m in \u001b[0;36membed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mEmbeddings\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \"\"\"\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/embeddings/huggingface.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_process\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_multi_process_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/embeddings/huggingface.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_process\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_multi_process_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'replace'"
          ]
        }
      ],
      "source": [
        "# --- Step 6: Example queries ---\n",
        "query = \"What is the volume of a box with a height of 6 cm, width 7 cm, and length 9 cm?\"\n",
        "print(\"\\nQuery:\", query)\n",
        "print(\"\\nAnswer:\", qa_chain.invoke({\"query\": query})[\"result\"])\n",
        "\n",
        "query2 = \"Who discovered calculus?\"\n",
        "print(\"\\nQuery:\", query2)\n",
        "print(\"\\nAnswer:\", qa_chain.invoke({\"query\": query2})[\"result\"])\n",
        "\n",
        "\n",
        "query3 = \"What is the result of 1+1\"\n",
        "print(\"\\nQuery:\", query3)\n",
        "print(\"\\nAnswer:\", qa_chain.invoke({\"query\": query3})[\"result\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XGofvjymR5SH",
      "metadata": {
        "id": "XGofvjymR5SH"
      },
      "outputs": [],
      "source": [
        "\n",
        "query4 = \"What is the integral of 4x \"\n",
        "print(\"\\nQuery:\", query4)\n",
        "print(\"\\nAnswer:\", qa_chain.invoke({\"query\": query4})[\"result\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r8VSg2gRXnxN",
      "metadata": {
        "id": "r8VSg2gRXnxN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}