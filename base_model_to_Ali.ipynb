{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e4beca8",
   "metadata": {},
   "source": [
    "## MATH Data Preprocess\n",
    "\n",
    "Make sure you get data from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7764bce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:\\AI Models\\Proj\\math_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]Downloading 'algebra/train-00000-of-00001.parquet' to 'math_dataset\\.cache\\huggingface\\download\\algebra\\train-00000-of-00001.parquet.73347f5b55869f21ff094361025dbd12d291e971aa4d72142eacee10438e449f.incomplete'\n",
      "Downloading 'geometry/test-00000-of-00001.parquet' to 'math_dataset\\.cache\\huggingface\\download\\geometry\\test-00000-of-00001.parquet.98720f3a8134ad9784fd8951195245264495df03ffc5c9485a9a54ff5ae2431a.incomplete'\n",
      "Downloading 'counting_and_probability/test-00000-of-00001.parquet' to 'math_dataset\\.cache\\huggingface\\download\\counting_and_probability\\test-00000-of-00001.parquet.c324818949c75a6227c0328a8499d58023cbbf6757cfc1736f5ab24cc8d87966.incomplete'\n",
      "Downloading 'counting_and_probability/train-00000-of-00001.parquet' to 'math_dataset\\.cache\\huggingface\\download\\counting_and_probability\\train-00000-of-00001.parquet.d37ae017930df41678edee50dcde18c17fb06afaff9eb505c1b95f1002bfcb31.incomplete'\n",
      "Downloading 'geometry/train-00000-of-00001.parquet' to 'math_dataset\\.cache\\huggingface\\download\\geometry\\train-00000-of-00001.parquet.9dbf5e5b55499e696e0ba72da9d85d4f0be3acbf7eaa6cb014b0fc78bb63784f.incomplete'\n",
      "Downloading 'algebra/test-00000-of-00001.parquet' to 'math_dataset\\.cache\\huggingface\\download\\algebra\\test-00000-of-00001.parquet.0e04a850dac9cfc758eac0c80afd2d0cc65e29ea72f916c8ac1045b12af937f5.incomplete'\n",
      "Downloading '.gitattributes' to 'math_dataset\\.cache\\huggingface\\download\\.gitattributes.28df5f900b358436f0267334b3e3e9af33f917ba.incomplete'\n",
      "Download complete. Moving file to math_dataset\\algebra\\train-00000-of-00001.parquet\n",
      "Download complete. Moving file to math_dataset\\.gitattributes\n",
      "\n",
      "Fetching 16 files:   6%|▋         | 1/16 [00:00<00:05,  2.91it/s]Download complete. Moving file to math_dataset\\counting_and_probability\\test-00000-of-00001.parquet\n",
      "Downloading 'intermediate_algebra/test-00000-of-00001.parquet' to 'math_dataset\\.cache\\huggingface\\download\\intermediate_algebra\\test-00000-of-00001.parquet.e859f72486c951c2017da880541ca729940eaa986b0364eb23e238983df9bfeb.incomplete'\n",
      "Downloading 'intermediate_algebra/train-00000-of-00001.parquet' to 'math_dataset\\.cache\\huggingface\\download\\intermediate_algebra\\train-00000-of-00001.parquet.0c87f3798ebdfb915b1f9b6fc13c1a8d064c3cb91631ccbe85b83ed5d71150f6.incomplete'\n",
      "Download complete. Moving file to math_dataset\\geometry\\test-00000-of-00001.parquet\n",
      "Downloading 'README.md' to 'math_dataset\\.cache\\huggingface\\download\\README.md.9ab6422553ffa7c65f5c11386d1599fc77149101.incomplete'\n",
      "Download complete. Moving file to math_dataset\\counting_and_probability\\train-00000-of-00001.parquet\n",
      "Download complete. Moving file to math_dataset\\intermediate_algebra\\test-00000-of-00001.parquet\n",
      "Downloading 'number_theory/train-00000-of-00001.parquet' to 'math_dataset\\.cache\\huggingface\\download\\number_theory\\train-00000-of-00001.parquet.81c08649149b39811f2d1d7ddf5dfccf6c4c8044a2e169cfb24db09160c941f4.incomplete'\n",
      "Download complete. Moving file to math_dataset\\algebra\\test-00000-of-00001.parquet\n",
      "Download complete. Moving file to math_dataset\\geometry\\train-00000-of-00001.parquet\n",
      "Download complete. Moving file to math_dataset\\number_theory\\train-00000-of-00001.parquet\n",
      "Downloading 'precalculus/test-00000-of-00001.parquet' to 'math_dataset\\.cache\\huggingface\\download\\precalculus\\test-00000-of-00001.parquet.da37474ba3761ae5727af3844a7ba963a735bd6a14c65e6137593669a4fe3b9c.incomplete'\n",
      "Downloading 'prealgebra/train-00000-of-00001.parquet' to 'math_dataset\\.cache\\huggingface\\download\\prealgebra\\train-00000-of-00001.parquet.765b526fb5c0b8385cb7be2c16bf4f6f28cf71f2bc15c826abfbb5fa7f8616cc.incomplete'\n",
      "Downloading 'prealgebra/test-00000-of-00001.parquet' to 'math_dataset\\.cache\\huggingface\\download\\prealgebra\\test-00000-of-00001.parquet.301e5d8ade5c7b5038032532e498bdc9dca799e7f1061a63f2e7d980803240cc.incomplete'\n",
      "Downloading 'precalculus/train-00000-of-00001.parquet' to 'math_dataset\\.cache\\huggingface\\download\\precalculus\\train-00000-of-00001.parquet.28bb1ff95525c8d32521509bef91de76339659f5467a381e6e8deea204538f0e.incomplete'\n",
      "Downloading 'number_theory/test-00000-of-00001.parquet' to 'math_dataset\\.cache\\huggingface\\download\\number_theory\\test-00000-of-00001.parquet.ba156c9c9fa2040836ba12135fd964e6e67d6bccd8c469ec4a3ad941f8f6fbe9.incomplete'\n",
      "Download complete. Moving file to math_dataset\\README.md\n",
      "\n",
      "Fetching 16 files:  12%|█▎        | 2/16 [00:00<00:06,  2.22it/s]Download complete. Moving file to math_dataset\\precalculus\\test-00000-of-00001.parquet\n",
      "Download complete. Moving file to math_dataset\\prealgebra\\test-00000-of-00001.parquet\n",
      "Download complete. Moving file to math_dataset\\number_theory\\test-00000-of-00001.parquet\n",
      "Download complete. Moving file to math_dataset\\precalculus\\train-00000-of-00001.parquet\n",
      "Download complete. Moving file to math_dataset\\intermediate_algebra\\train-00000-of-00001.parquet\n",
      "\n",
      "Fetching 16 files:  62%|██████▎   | 10/16 [00:01<00:00, 11.89it/s]Download complete. Moving file to math_dataset\\prealgebra\\train-00000-of-00001.parquet\n",
      "\n",
      "Fetching 16 files:  88%|████████▊ | 14/16 [00:01<00:00, 15.35it/s]\n",
      "Fetching 16 files: 100%|██████████| 16/16 [00:01<00:00, 12.85it/s]\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli download EleutherAI/hendrycks_math --repo-type dataset --local-dir ./math_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32791f35",
   "metadata": {},
   "source": [
    "Now we preprocess the data to make it into the desired format for SFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f1ac5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import load_dataset, get_dataset_config_names, concatenate_datasets\n",
    "import tiktoken\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e104acab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN – algebra: 1744 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 771/771 [00:00<00:00, 75660.57 examples/s]\n",
      "Generating test split: 100%|██████████| 474/474 [00:00<00:00, 48802.10 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN – counting_and_probability: 771 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 870/870 [00:00<00:00, 113430.04 examples/s]\n",
      "Generating test split: 100%|██████████| 479/479 [00:00<00:00, 80536.82 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN – geometry: 870 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 1295/1295 [00:00<00:00, 121796.21 examples/s]\n",
      "Generating test split: 100%|██████████| 903/903 [00:00<00:00, 88740.78 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN – intermediate_algebra: 1295 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 869/869 [00:00<00:00, 86134.09 examples/s]\n",
      "Generating test split: 100%|██████████| 540/540 [00:00<00:00, 39485.44 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN – number_theory: 869 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 1205/1205 [00:00<00:00, 138899.51 examples/s]\n",
      "Generating test split: 100%|██████████| 871/871 [00:00<00:00, 91310.42 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN – prealgebra: 1205 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 746/746 [00:00<00:00, 94661.79 examples/s]\n",
      "Generating test split: 100%|██████████| 546/546 [00:00<00:00, 57125.15 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN – precalculus: 746 examples\n",
      "TRAIN total: 7500 examples\n",
      "TEST – algebra: 1187 examples\n",
      "TEST – counting_and_probability: 474 examples\n",
      "TEST – geometry: 479 examples\n",
      "TEST – intermediate_algebra: 903 examples\n",
      "TEST – number_theory: 540 examples\n",
      "TEST – prealgebra: 871 examples\n",
      "TEST – precalculus: 546 examples\n",
      "TEST total: 5000 examples\n"
     ]
    }
   ],
   "source": [
    "configs = get_dataset_config_names(\"EleutherAI/hendrycks_math\")\n",
    "def load_all(split: str):\n",
    "    parts = []\n",
    "    for cfg in sorted(configs):\n",
    "        ds = load_dataset(\"EleutherAI/hendrycks_math\", cfg, split=split)\n",
    "        print(f\"{split.upper()} – {cfg}: {len(ds)} examples\")\n",
    "        parts.append(ds)\n",
    "    full = concatenate_datasets(parts)\n",
    "    print(f\"{split.upper()} total: {len(full)} examples\")\n",
    "    return full\n",
    "\n",
    "train_ds = load_all(\"train\")\n",
    "test_ds  = load_all(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ef921c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = (\n",
    "    \"You are a math assistant. Solve the problem step by step, \"\n",
    "    \"explain your reasoning, and box the final answer using \\\\boxed{}.\"\n",
    ")\n",
    "MAX_TOKENS = 4000\n",
    "ENC = tiktoken.get_encoding(\"cl100k_base\")\n",
    "OUT_TRAIN = Path(\"MATH_train_full.jsonl\")\n",
    "OUT_TEST  = Path(\"MATH_test_full.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f557826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing MATH_train_full.jsonl: 100%|██████████| 7500/7500 [00:05<00:00, 1256.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500 lines → MATH_train_full.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing MATH_test_full.jsonl: 100%|██████████| 5000/5000 [00:03<00:00, 1333.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 lines → MATH_test_full.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def write_jsonl(ds, out_path):\n",
    "    kept = 0\n",
    "    with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for ex in tqdm(ds, desc=f\"Writing {out_path.name}\"):\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\",   \"content\": ex[\"problem\"]},\n",
    "                {\"role\": \"assistant\",\"content\": ex[\"solution\"]}\n",
    "            ]\n",
    "            # ---- token guard (preserve \\boxed{}) ----\n",
    "            txt = json.dumps({\"messages\": messages}, ensure_ascii=False)\n",
    "            if len(ENC.encode(txt)) > MAX_TOKENS:\n",
    "                sol = ex[\"solution\"]\n",
    "                if \"\\\\boxed{\" in sol:\n",
    "                    start = sol.rfind(\"\\\\boxed{\")\n",
    "                    # 保留答案前 200 字 + 答案\n",
    "                    before = sol[max(0, start - 200):start]\n",
    "                    after = sol[start:]  # 包含 \\boxed{...}\n",
    "                    sol = before + \"\\n...\\n\" + after\n",
    "                else:\n",
    "                    # 极少情况：无 boxed\n",
    "                    sol = sol[:MAX_TOKENS*4] + \"\\n...\"\n",
    "                messages[-1][\"content\"] = sol\n",
    "                txt = json.dumps({\"messages\": messages}, ensure_ascii=False)\n",
    "            f.write(txt + \"\\n\")\n",
    "            kept += 1\n",
    "    print(f\"{kept} lines → {out_path}\")\n",
    "\n",
    "write_jsonl(train_ds, OUT_TRAIN)\n",
    "write_jsonl(test_ds,  OUT_TEST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSE595",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
